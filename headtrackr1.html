<!DOCTYPE html>
<html lang="en" data-xlabs-extension="1" data-xlabs-extension-ready="1" data-xlabs-extension-version="2.5.5"><head>
	<title>facetracking</title>
	<meta http-equiv="X-UA-Compatible" content="IE=Edge">
	<meta charset="utf-8">
	<style>
		body {
			background-color: #f0f0f0;
			margin-left: 10%;
			margin-right: 10%;
			margin-top: 5%;
			width: 40%;
			overflow: hidden;
			font-family: "Helvetica", Arial, Serif;
			position: relative;
		}
	</style>
	<script>
		// getUserMedia only works over https in Chrome 47+, so we redirect to https. Also notify user if running from file.
		if (window.location.protocol == "file:") {
			alert("You seem to be running this example directly from a file. Note that these examples only work when served from a server or localhost due to canvas cross-domain restrictions.");
		} else if (window.location.hostname !== "localhost" && window.location.protocol !== "https:"){
			window.location.protocol = "https";
		}
	</script>
	<script type="text/javascript">

	var _gaq = _gaq || [];
	_gaq.push(['_setAccount', 'UA-32642923-1']);
	_gaq.push(['_trackPageview']);

	(function() {
		var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
		ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
		var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
	})();

	</script>
	
	<style>canvas {position: absolute;top: 0px;left: 0px;-o-transform : scaleX(-1);-webkit-transform : scaleX(-1);transform : scaleX(-1);-ms-filter : fliph; /*IE*/filter : fliph; /*IE*/}
			video {-o-transform : scaleX(-1);-webkit-transform : scaleX(-1);transform : scaleX(-1);-ms-filter : fliph; /*IE*/filter : fliph; /*IE*/}</style>
	<style type="text/css">#xLabsCanvas{pointer-events:none;top:0;left:0;position:fixed;z-index:2147483646;}#xLabsCanvas.allow-pointer{pointer-events:auto;}</style>
	
	<!-- This includes Flocking and all its dependencies, including jQuery 2.1.3 and Infusion -->
    <script src="/headtracker/dist/flocking-all.js"></script>    
    <script src="/headtracker/sounds/impulse.js" type="text/javascript"></script>

</head>
<body>
	<script src="/headtracker/js/headtrackr.js"></script>
	
	<canvas id="compare" width="640" height="480" style="display:none"></canvas>
	<video id="vid" autoplay="" loop="" width="640" height="480"></video>
	<canvas id="overlay" width="640" height="480" style="position: absolute; top: 0px; z-index: 100001; display: block;"></canvas>
	<canvas id="debug" width="640" height="480" style="position: absolute; top: 0px; z-index: 100002; display: none;"></canvas>

	<p><input type="button" onclick="htracker.stop();htracker.start();" value="Reiniciar Facedetection">
	<br><br>
	<p id="gUMMessage"></p>
	<p>Status : <span id="headtrackerMessage">Tracking face</span></p>

	<p id="pos1"></p>
	<p id="pos2"></p>
	<p id="pos3"></p>

	<script>
		(function () {

		    "use strict";

		    fluid.registerNamespace("sound1");

		    var environment = flock.init();

		    sound1.play = function () {
		        var synth = flock.synth({
		            synthDef: {
		                ugen: "flock.ugen.impulse",
		                freq: {
		                    ugen: "flock.ugen.xLine",
		                    start: 580,
		                    end: 0.1,
		                    duration: 1.0
		                },
		                mul: 0.25
		            }
		        });
		        
		        environment.start();
		    };

		}());
		sound1.play();
	</script>
	
	<script>
		var videoInput = document.getElementById('vid');
		var canvasInput = document.getElementById('compare');
		var canvasOverlay = document.getElementById('overlay')
		var debugOverlay = document.getElementById('debug');
		var overlayContext = canvasOverlay.getContext('2d');
		canvasOverlay.style.position = "absolute";
		canvasOverlay.style.top = '0px';
		canvasOverlay.style.zIndex = '100001';
		canvasOverlay.style.display = 'block';
		debugOverlay.style.position = "absolute";
		debugOverlay.style.top = '0px';
		debugOverlay.style.zIndex = '100002';
		debugOverlay.style.display = 'none';
		
		statusMessages = {
			"whitebalance" : "checking for stability of camera whitebalance",
			"detecting" : "Detecting face",
			"hints" : "Hmm. Detecting the face is taking a long time",
			"redetecting" : "Lost track of face, redetecting",
			"lost" : "Lost track of face",
			"found" : "Tracking face"
		};
		
		supportMessages = {
			"no getUserMedia" : "Unfortunately, <a href='http://dev.w3.org/2011/webrtc/editor/getusermedia.html'>getUserMedia</a> is not supported in your browser. Try <a href='http://www.opera.com/browser/'>downloading Opera 12</a> or <a href='http://caniuse.com/stream'>another browser that supports getUserMedia</a>. Now using fallback video for facedetection.",
			"no camera" : "No camera found. Using fallback video for facedetection."
		};
		
		document.addEventListener("headtrackrStatus", function(event) {
			if (event.status in supportMessages) {
				var messagep = document.getElementById('gUMMessage');
				messagep.innerHTML = supportMessages[event.status];
			} else if (event.status in statusMessages) {
				var messagep = document.getElementById('headtrackerMessage');
				messagep.innerHTML = statusMessages[event.status];
			}
		}, true);
		
		var htracker = new headtrackr.Tracker({altVideo : {ogv : "./media/capture5.ogv", mp4 : "./media/capture5.mp4"}, calcAngles : true, ui : false, headPosition : false, debug : debugOverlay});
		htracker.init(videoInput, canvasInput);
		htracker.start();
		
		document.addEventListener("facetrackingEvent", function( event ) {
			var message1 = document.getElementById('pos1');
			var message2 = document.getElementById('pos2');
			var message3 = document.getElementById('pos3');

			overlayContext.clearRect(0,0,640,480);

			if (event.detection == "CS") {
				overlayContext.translate(event.x, event.y)
				overlayContext.rotate(event.angle-(Math.PI/2));
				overlayContext.strokeStyle = "#00CC00";
				overlayContext.strokeRect((-(event.width/2)) >> 0, (-(event.height/2)) >> 0, event.width, event.height);
				overlayContext.rotate((Math.PI/2)-event.angle);
				overlayContext.translate(-event.x, -event.y);
			}
			message1.innerHTML = "Head position in X axis: " + event.x;	
			message2.innerHTML = "Head position in Y axis: " + event.y;
			
			//Separamos la pantalla en 4 partes. Cada una proporciona un sonido diferente:
			if (event.x < videoInput.width/2) {
				if (event.y < videoInput.height/2) {
					message3.innerHTML = "esquina arriba derecha";					
					sound1.play();
				} else {
					message3.innerHTML = "esquina abajo derecha";		
				}
			} else {
				if (event.y < videoInput.height/2) {
					message3.innerHTML = "esquina arriba izquierda";
				} else {
					message3.innerHTML = "esquina abajo izquierda";				
					sound1.play();
				}
			}
		});
	</script>


	<canvas id="xLabsCanvas" width="1366" height="275" style="display: none; width: 1366px; height: 275px; background: 0px 50%;"></canvas>
</body>
</html>